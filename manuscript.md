---
author-meta:
- Glenn Hickey
- David Heller
- Jean Monlong
- Jonas Andreas Sibbesen
- Jouni Siren
- Jordan Eizenga
- Eric Dawson
- Erik Garrison
- Adam Novak
- Benedict Paten
date-meta: '2019-05-15'
keywords:
- structural variation
- pangenome
- variant genotyping
lang: en-US
title: Genotyping structural variation in variation graphs with the vg toolkit
...







<small><em>
This manuscript
([permalink](https://jmonlong.github.io/manu-vgsv/v/9e46e79e60be3758d0475ca468dfac9b7e7ebf71/))
was automatically generated
from [jmonlong/manu-vgsv@9e46e79](https://github.com/jmonlong/manu-vgsv/tree/9e46e79e60be3758d0475ca468dfac9b7e7ebf71)
on May 15, 2019.
</em></small>

## Authors


[![ORCID icon](images/orcid.svg){height="11px" width="11px"}](https://orcid.org/XXXX-XXXX-XXXX-XXXX)
Glenn Hickey<sup>1,☯</sup>,
[![ORCID icon](images/orcid.svg){height="11px" width="11px"}](https://orcid.org/XXXX-XXXX-XXXX-XXXX)
David Heller<sup>1,2,☯</sup>,
[![ORCID icon](images/orcid.svg){height="11px" width="11px"}](https://orcid.org/XXXX-XXXX-XXXX-XXXX)
Jean Monlong<sup>1,☯</sup>,
[![ORCID icon](images/orcid.svg){height="11px" width="11px"}](https://orcid.org/XXXX-XXXX-XXXX-XXXX)
Jonas Andreas Sibbesen<sup>1</sup>,
[![ORCID icon](images/orcid.svg){height="11px" width="11px"}](https://orcid.org/XXXX-XXXX-XXXX-XXXX)
Jouni Siren<sup>1</sup>,
[![ORCID icon](images/orcid.svg){height="11px" width="11px"}](https://orcid.org/XXXX-XXXX-XXXX-XXXX)
Jordan Eizenga<sup>1</sup>,
[![ORCID icon](images/orcid.svg){height="11px" width="11px"}](https://orcid.org/XXXX-XXXX-XXXX-XXXX)
Eric Dawson<sup>3</sup>,
[![ORCID icon](images/orcid.svg){height="11px" width="11px"}](https://orcid.org/XXXX-XXXX-XXXX-XXXX)
Erik Garrison<sup>1</sup>,
[![ORCID icon](images/orcid.svg){height="11px" width="11px"}](https://orcid.org/XXXX-XXXX-XXXX-XXXX)
Adam Novak<sup>1</sup>,
[![ORCID icon](images/orcid.svg){height="11px" width="11px"}](https://orcid.org/XXXX-XXXX-XXXX-XXXX)
Benedict Paten<sup>1,†</sup>

<sup>☯</sup> --- These authors contributed equally to this work

<sup>†</sup> --- To whom correspondence should be addressed: bpaten@ucsc.edu
<small>


1. UC Santa Cruz Genomics Institute, University of California, Santa Cruz, California, USA
2. Max Planck Institute for Molecular Genetics, Berlin, Germany
3. Department of Genetics, University of Cambridge, Cambridge, UK

</small>


## Abstract {.page_break_before}

Structural variants (SVs) are significant components of genetic diversity and have been associated with diseases, but the technological challenges surrounding their representation and identification make them difficult to study relative to point mutations. 
Still, thousands of SVs have been characterized, and catalogs continue to improve with new technologies.
In parallel, variation graphs have been proposed to represent human pan-genomes, offering reduced reference bias and better mapping accuracy than linear reference genomes. 
We contend that variation graphs provide an effective means for leveraging SV catalogs for short-read SV genotyping experiments.
In this work, we extend vg (a software toolkit for working with variation graphs) to support SV genotyping.
We show that it is capable of genotyping insertions, deletions and inversions, even in the presence of small errors in the location of the SVs breakpoints.
We then benchmark vg against state-of-the-art SV genotypers using three high-quality sequence-resolved SV catalogs generated by recent studies ranging up to 97,368 variants in size.
Our results show that vg produced the best genotype predictions systematically in all datasets.
In addition, we use assemblies from 12 yeast strains to show that graphs constructed directly from aligned de novo assemblies can improve genotyping compared to graphs built from intermediate SV catalogs in the VCF format.
Our results demonstrate the power of variation graphs for SV genotyping.
Beyond single nucleotide variants and short insertions/deletions, the vg toolkit now incorporates SVs in its unified variant calling framework and provides a natural solution to integrate high-quality SV catalogs and assemblies.



## Introduction {.page_break_before}

A structural variant (SV) is a genomic mutation involving 50 or more base pairs.
SVs can take several forms such as deletions, insertions, inversions, translocations or other complex events.  
Due to their greater size, SVs often have a larger impact on phenotype than smaller events such as single nucleotide variants (SNVs) and small insertions and deletions (indels)[@2gpKwL67].
Indeed, SVs have long been associated with developmental disorders, cancer and other complex diseases and phenotypes[@ebc66eBr]. 

Despite their importance, SVs remain much more poorly studied than their smaller mutational counterparts.
This discrepancy stems from technological limitations: Short read sequencing has provided the basis of most modern genome sequencing studies due to its high base-level accuracy and relatively low cost, however, it is poorly suited for discovering SVs. 
The central obstacle is in mapping short reads to the human reference genome.
It is generally difficult or impossible to unambiguously map a short read if the sample whose genome is being analyzed differs substantially from the reference at the read's location.
The large size of SVs virtually guarantees that this will be the case.
For example, if the read derives from the middle of a large insertion relative to the reference, there is no sequence in the reference that corresponds to a correct mapping.
The best result a read mapper could hope to produce would be to leave it unmapped.
Moreover, SVs often lie in repeat-rich regions, which further frustrate read mapping algorithms.

Short reads can be more effectively used to genotype known SVs.
This is important, as even though efforts to catalog SVs with other technologies have been highly successful, their cost currently prohibits their use in large-scale studies that require hundreds or thousands of samples such as disease association studies.
Traditional SV genotypers start from reads that were mapped to a reference genome, extracting aberrant mapping that might support the presence of the SV of interest.
State-of-art methods like SVTyper[@AltPnocw] and Delly[@nLvQCjXU] typically focus on split reads and paired reads mapped too close or too far from each other.
These discordant reads are tallied and remapped to the reference sequence modified with the SV of interest in order to genotype deletions, insertions, duplications, inversions and translocations.
SMRT-SV2 uses a different approach: the reference genome is augmented with SV-containing sequences as alternate contigs and the resulting mappings are evaluated with a machine learning model trained for this purpose[@3NNFS6U2].

The catalog of known SVs in human is quickly expanding.
Several large-scale projects have used short-read sequencing and extensive discovery pipelines on large cohorts, compiling catalogs with tens of thousands of SVs in humans[@qA6dWFP; @py6BC5kj].
More recent studies using long-read or linked-read sequencing have produced large catalogs of structural variation, the majority of which was novel and sequence-resolved[@z91V6jjU; @rs7e40wC; @PRx3qEIm; @121OWcTA4; @3NNFS6U2].
These technologies are also enabling the production of high-quality de novo genome assemblies[@z91V6jjU; @6KbgcueR], and large blocks of haplotype-resolved sequences[@Pu6SY37C].
Such technical advances promise to expand the amount of known genomic variation in humans in the near future, and further power SV genotyping studies.
Representing known structural variation in the wake of increasingly larger datasets poses a considerable challenge, however.
VCF, the standard format for representing small variants, is unwieldy when used for SVs due its unsuitability for expressing nested or complex variants.
Another strategy consists in incorporating SVs into a linear pan-genome reference via alt contigs, but it also has serious drawbacks.
Alt contigs tend to increase mapping ambiguity.
In addition, it is unclear how to scale this approach as SV catalogs grow.

Pan-genome graph reference representations offer an attractive approach for storing genetic variation of all types[@Qa8mx6Ll]. 
The graph structure can represent SVs as succinctly and directly as point mutations. 
Moreover, including known variants in the reference makes both read mapping and variant calling variant-aware.
This leads to benefits in terms of accuracy and sensitivity[@10jxt15v0; @DuODeStx; @11Jy8B61m].
In addition, different variant types can be called simultaneously and scored consistently across types by a unified framework.

vg is the first openly available variation graph tool to scale to multi-gigabase genomes.
It provides read mapping, variant calling and visualization tools[@10jxt15v0].
In addition, vg can build graphs both from variant catalogs in the VCF format and from assembly alignments.

Other tools have used genome graphs specifically to genotype variants.
GraphTyper realigns mapped reads to a graph built from known SNVs and short indels using a sliding-window approach[@ohTIiqfV].
BayesTyper first builds a set of graphs from known variants including SVs, then genotypes variants by comparing the distribution of k-mers in the sequencing reads with the k-mers of haplotype candidate paths in the graph[@14Uxmwbxm].
These graph-based approaches showed clear advantages over standard methods that use only the linear reference.

In this work, we present a variation graph-based SV genotyping framework implemented using vg. 
We show that this method is capable of genotyping known deletions, insertions and inversions.
This is true even when there is small errors in the location of the SVs breakpoints.
Starting from SVs discovered in recent long-read sequencing studies[@3NNFS6U2;@vQTymKCj;@14neTdqfN;@16GvGhO20], we evaluated the genotyping accuracy using simulated and real Illumina reads. 
We also compared vg's performance with state-of-the-art SV genotypers: SVTyper[@AltPnocw], Delly[@nLvQCjXU], BayesTyper[@14Uxmwbxm] and SMRT-SV2[@3NNFS6U2].
Across these three datasets that we tested, which range in size from 26k to 97k SVs, vg is the best performing SV genotyper on real short-read data for all SV types.
In addition, we show that building graphs from the alignment of de novo assemblies leads to better genotyping performance.



## Results

### Structural variation in vg

We used vg to implement a simple SV genotyping pipeline.
Reads are mapped to the graph and used to compute the read support for each node and edge (see [Supplementary Information](#supplementary-information) for a description of the graph formalism).
Sites of variation are then identified using the snarl decomposition as described in [@xJlNnKH2].
For each site, the two most supported paths (haplotypes) are determined, and their relative supports used to produce a genotype at that site (Figure {@fig:1}a).
The pipeline is described in more detail in [Methods](#toil-vg).
We rigorously evaluated the accuracy of our method on a variety of datasets, and the results are presented in the remainder of this section.

![**Structural variation in vg.** 
a) vg uses the read coverage over possible paths to genotype variants in a "bubble" (or snarl). The cartoon depicts the case of an heterozygous insertion and an homozygous deletion. The algorithm is described in more details in [Methods](#toil-vg-call).
b) Simulation experiment. Each subplot shows a comparison of genotyping accuracy for four SV calling methods. Results are separated between types of variation (insertions, deletions, and inversions). The experiments were also repeated with small random errors introduced to the VCF to simulate breakpoint uncertainty. For each experiment, the y-axis shows the maximum F1 across different minimum quality thresholds.
](images/panel1.png){#fig:1}

### Simulated dataset

As a proof-of-concept, we simulated genomes and different types of SVs with a size distribution matching real SVs[@vQTymKCj].
We compared vg against SVTyper, Delly, and BayesTyper across different levels of sequencing depth.
We also added some errors at the breakpoints to investigate their effect on genotyping accuracy (see [Methods](#simulation-experiment)).
The results are shown in Figure {@fig:1}b.

When using the correct breakpoints, vg tied with Delly as the best genotyper for deletions, and with BayesTyper as the best genotyper for insertions.
For inversions, vg was the second best genotyper after BayesTyper.
The differences between the methods were the most visible at lower sequencing depth. 
In the presence of 1-10 bp errors in the breakpoint locations, the performance of Delly and BayesTyper dropped significantly (Figure {@fig:1}b).
The dramatic drop for BayesTyper can be explained by its k-mer-based approach that requires precise breakpoints.
In contrast, vg was only slightly affected by the presence of errors.
For vg, the F1 scores for all SV types decreased no more than 0.07.
Overall, these results show that vg is capable of genotyping SVs and is robust to breakpoint inaccuracies in the input VCF.

### HGSVC dataset

72,485 structural variants from The Human Genome Structural Variation Consortium (HGSVC) were used to benchmark the genotyping performance of vg against the three other SV genotyping methods.
This high-quality SV catalog was generated from three samples using a consensus from different sequencing, phasing, and variant calling technologies[@vQTymKCj]. 
The three samples come from different human populations: a Han Chinese individual (HG00514), a Puerto-Rican individual (HG00733), and a Yoruban Nigerian individual (NA19240).
We used these SVs to construct a graph with vg and as input for the other genotypers.
Using short sequencing reads, the SVs were genotyped and compared with the genotypes in the original catalog (see [Methods](#hgsvc-analysis)).

First we compared the methods using simulated reads for HG00514.
This represents the ideal situation where the SV catalog exactly matches the SVs supported by the reads.
While vg outperformed Delly and SVTyper, BayesTyper showed the best F1 score and precision-recall trade-off (Figures {@fig:2} and {@fig:hgsvc-sim-geno}, Table {@tbl:hgsvc}).
When restricting the comparisons to regions not identified as tandem repeats or segmental duplications, the genotyping predictions were significantly better for all methods, with vg almost as good as BayesTyper on deletions (F1 of 0.944 vs 0.955).
We observed similar results when evaluating the presence of an SV call instead of the exact genotype (Figures {@fig:2} and {@fig:hgsvc-sim}).
Overall, both graph-based methods, vg and BayesTyper, outperformed the other two methods tested.

![**Structural variants from the HGSVC and Genome in a Bottle datasets**. 
HGSVC: Simulated and real reads were used to genotype SVs and compared with the high-quality calls from Chaisson et al.[@vQTymKCj].
Reads were simulated from the HG00514 individual.
Using real reads, the three HG00514, HG00733, and NA19240 individuals were tested.
GiaB: Real reads from the HG002 individual were used to genotype SVs and compared with the high-quality calls from the Genome in a Bottle consortium[@14neTdqfN;@16GvGhO20].
Maximum F1 score for each method (color), across the whole genome or focusing on non-repeat regions (x-axis). 
We evaluated the ability to predict the presence of an SV (transparent bars) and the exact genotype (solid bars).
Results are separated across panels by variant type: insertions and deletions.
SVTyper cannot genotype insertions, hence the missing bars in the top panels.
](images/hgsvc-giab-best-f1.png){#fig:2}

We then repeated the analysis using real Illumina reads from the three HGSVC samples to benchmark the methods on a more realistic experiment.
Here vg clearly outperformed other approaches (Figures {@fig:2} and  {@fig:hgsvc-real-geno}).
In non-repeat regions and across the whole genome, the F1 scores and precision-recall AUC were higher for vg compared to other methods. 
For example, for deletions in non-repeat regions, the F1 score for vg was 0.801 while the second best method, Delly, had a F1 score of 0.692.
We observed similar results when evaluating the presence of an SV call instead of the exact genotype (Figures {@fig:2} and {@fig:hgsvc-real}).
Figure {@fig:hgsvc-ex} shows examples of an exonic deletion and an exonic insertion that were correctly genotyped by vg but not by the other methods.

![**Exonic SVs in the HGSVC dataset correctly genotyped by vg**. 
The red and blue bars represent read mapped to the graph whose topology is shown at the bottom in black.
Between the graph and the reads, a colored horizontal bar shows the path followed by the reference genome (GRCh38).
a) 51 bp homozygous deletion in the last exon of the LONRF2 gene.
b) 114 bp homozygous insertion in a short tandem repeat region overlapping the first exon of the MED13L gene, a gene predicted to be loss of function intolerant.
The vg read mappings show consistent coverage even over these SVs.
](images/panel7.png){#fig:hgsvc-ex}


### Other long-read datasets

#### Genome in a Bottle Consortium

The Genome in a Bottle (GiaB) consortium is currently producing a high-quality SV catalog for an Ashkenazim individual (HG002)[@14neTdqfN;@16GvGhO20].
Dozens of SV callers and datasets from short, long and linked reads were used to produce this set of SVs.
We evaluated the SV genotyping methods on this sample as well using the GIAB VCF, which also contains parental calls (totalling 26,359 SVs).
vg performed similarly on this dataset as on the HGSVC dataset, with a F1 score of 0.75 for both insertions and deletions in non-repeat regions (Figures {@fig:2}, {@fig:giab-geno} and {@fig:giab}, and Table {@tbl:giab}).
As before, other methods produced lower F1 scores in most cases, although Delly and BayesTyper predicted better genotypes for deletions in non-repeat regions.

#### Audano, et al. [@3NNFS6U2]

A recent study by Audano et al. generated catalog of 97,368 SVs using long-read sequencing across 15 individuals[@3NNFS6U2].
These variants were then genotyped from short reads across 440 individuals using SMRT-SV2, a machine learning-based genotyper implemented for that study.
SMRT-SV2 was trained on a pseudo-diploid genome constructed from high quality assemblies of two haploid cell lines.
We first called SVs in this dataset, using the same SV catalog and short read dataset.
vg was systematically better at predicting the presence of an SV for both SV types, but SMRT-SV2 produced better genotypes for deletions (see Figures {@fig:chmpd-svpop}, {@fig:chmpd-geno} and {@fig:chmpd}, and Table {@tbl:chmpd}). 
Using publicly available Illumina reads, we then genotyped SVs in 3 of the 15 individuals that were used for discovery in Audano et al.[@3NNFS6U2].

Compared to SMRT-SV2, vg had a better precision-recall curve and a higher F1 for both insertions and deletions (SVPOP in Figures {@fig:chmpd-svpop} and {@fig:svpop}, and Table {@tbl:svpop}).
Of note, SMRT-SV2 produces *no-calls* in regions where the read coverage is too low, and we observed that its recall increased when filtering these regions out the input set.
Interestingly, vg performed well even in regions where SMRT-SV2 produced *no-calls* (Figure {@fig:svpop-regions} and Table {@tbl:svpop-regions}).
Finally, Audano et al. identified 217 sequence-resolved inversions.
vg correctly predicted the presence of around 14% of the inversions present in the three samples (Table {@tbl:svpop}).
Inversions are often complex, harboring additional variation that makes their characterization and genotyping challenging.

![**Structural variants from Audano et al.[@3NNFS6U2]**.
The pseudo-diploid genome built from two CHM cell lines and one negative control sample was originally used to train SMRT-SV2 in Audano et al.[@3NNFS6U2].
It contains 16,180 SVs.
The SVPOP panel shows the combined results for the HG00514, HG00733, and NA19240 individuals, 3 of the 15 individuals used to generate the high-quality SV catalog in Audano et al.[@3NNFS6U2].
Maximum F1 score for each method (color), across the whole genome or focusing on non-repeat regions (x-axis). 
We evaluated the ability to predict the presence of an SV (transparent bars) and the exact genotype (solid bars).
Genotype information is not available in the SVPOP catalog hence genotyping performance could not be evaluated.
](images/chmpd-svpop-best-f1.png){#fig:chmpd-svpop}

### Graphs from alignment of de novo assemblies

Genome graphs can be constructed directly from multiple sequence alignments of de novo assemblies[@10jxt15v0].
This bypasses the need for generating an explicit variant catalog relative to a linear reference, which could be a source of error (for example, from reference bias during read mapping and variant calling).
Furthermore, genome alignments from graph-based software such as Cactus [@1FgS53pXi] can contain complex structural variation that is extremely difficult to represent, let alone call, outside of a graph.
We therefore investigated whether genome graphs derived from alignments of de-novo assemblies yield advantages for SV genotyping.

We analyzed public sequencing datasets for 12 yeast strains from two related clades (*S. cerevisiae* and *S. paradoxus*) [@7f5OKa5O].
We compared genotyping results using two different types of genome graphs.
The graphs were constructed using 5 of the 12 strains.
*S.c. S288C* was used as the reference strain, and we selected two other strains from each of the two clades (see [Methods](#yeast-graph-analysis)).
The first graph (called *VCF graph* below) was created from the linear reference genome of the *S.c. S288C* strain and a set of SVs relative to this reference strain in VCF format identified by three methods: Assemblytics [@krO7WgVi], AsmVar [@oVaXIwl5] and paftools [@172cJaw4Q].
The second graph (called *cactus graph* below) was derived from a multiple genome alignment of the five strains using Cactus [@1FgS53pXi].
The *VCF graph* is mostly linear and highly dependent on the reference genome.
In contrast, the *cactus graph* is structurally complex and relatively free of reference bias.

First, we tested our hypothesis that the *cactus graph* has higher mappability due to its better representation of sequence diversity among the yeast strains (see [Supplementary Information](#mappability-comparison-between-yeast-graphs)).
Generally, more reads mapped to the *cactus graph* with high identity (Figure {@fig:panel3}a) and high mapping quality (Figure {@fig:panel3}b) than to the *VCF graph*.

Next, we compared the SV genotyping performance of both graphs.
We mapped short reads from the 11 non-reference strains to both graphs and called variants for each strain using the vg toolkit's variant calling module (see [Methods](#toil-vg-call)).
There is no gold standard call set for these sample, so we used an indirect measure of SV calling accuracy.
We evaluated each call set based on the alignment of reads to a *sample graph* constructed from the call set (see [Methods](#calling-and-genotyping-of-svs)).
If a given call set is correct, we expect that reads from the same sample will be mapped with high identity and confidence to the corresponding sample graph.
Therefore, we compared the average percent identity and mapping quality of the short reads on each sample graph (Figures {@fig:4}a and b).
Similar to the mappability results, the *cactus graph* clearly outperformed the *VCF graph* for strains in the *S. paradoxus* clade and performed slightly better for strains in the *S. cerevisiae* clade.
While the higher percent identity shows that the *cactus graph* represents the reads better (Figures {@fig:4}a), the higher mapping quality confirms that this did not come at the cost of added ambiguity or a more complex graph (Figures {@fig:4}b).
Our results did not show a substantial difference between strains included in the graph and those that were excluded.
This suggests that two strains from each clade as well as the reference strain are sufficient to capture most of the genetic variation among all the strains.
For a direct comparison, see Figure {@fig:panel6} which shows results of the same experiment on graphs generated from all 12 strains.

![**SV genotyping comparison.**
Short reads from all 11 non-reference yeast strains were used to genotype SVs contained in both graphs. 
Subsequently, sample graphs were generated from the resulting SV callsets. 
The short reads were aligned to the sample graphs and the quality of the alignments was used to ascertain genotyping performance.
More accurate genotypes should result in reference graphs that have mappings with high identity and confidence for a greater proportion of the reads.
a) Average mapping identity of short reads aligned to the sample graphs derived from *cactus graph* (y-axis) and *VCF graph* (x-axis).
b) Average mapping quality of short reads aligned to the sample graphs derived from *cactus graph* (y-axis) and *VCF graph* (x-axis).
Colors and shapes represent the 11 non-reference strains and two clades, respectively. 
Transparency indicates whether the strain was used to construct the graphs.
](images/panel4.png){#fig:4}



## Discussion

<!-- Discuss why vg is doing better -->
Overall, vg was the most accurate SV genotyper in our benchmarks.
These results show that variant calling benefits from variant-aware read mapping, a finding consistent with previous studies[@10jxt15v0; @DuODeStx; @11Jy8B61m; @ohTIiqfV; @14Uxmwbxm].
We took advantage of newly released datasets for our evaluation, which feature up to 3.7 times more variants than more widely-used GIAB benchmark.
More and more large-scale projects are using low cost short-read technologies to sequence the genomes of thousands to hundreds of thousands of individuals (e.g. the Pancancer Analysis of Whole Genomes[@10Jid8Wql], the Genomics England initiative[@mWj2p7Xp], and the TOPMed consortium[@ir1O1h8n]).
We believe pangenome graph-based approaches will improve both how efficiently SVs can be represented, and how accurately they can be genotyped with this type of data.

<!-- Input data quality: "sequence-resolved", break-point fine-tuning. -->
A particular advantage of our method is that it does not require exact breakpoint resolution in the variant library.
Our simulations showed that vg's SV genotyping algorithm is robust to errors of as much as 10 bp in breakpoint location.
However, there is an upper limit.
vg cannot accurately genotype variants with much higher uncertainty in the breakpoint location (like those discovered through read coverage analysis).
Of note, vg is also capable of fine-tuning SV breakpoints by augmenting the graph with differences observed in read alignments.
Simulations showed that this approach can usually correct small errors in SV breakpoints (Figure {@fig:simerror-bkpt} and Table {@tbl:simerror-bkpt}).

<!-- Already superior but will only get better with new vg dev -->
vg uses a unified framework to call and score different variant types simultaneously.
In this work, we only considered graphs containing certain types of SVs, but the same methods can be extended to a broader range of graphs.
For example, we are interested in evaluating how genotyping SVs together with SNPs and small indels using a combined graph effects the accuracy of studying either alone.
The same methods used for genotyping known variants in this work can also be extended to call novel variants by first augmenting the graph with edits from the mapped reads.
This approach, which was used only in the breakpoint fine-tuning portion of this work, could be further used to study small variants around and nested within SVs.
Novel SVs could be called by augmenting the graph with long-read mappings.
vg is entirely open source, and there is a growing community of developers and users working together to constantly improve it.
We expect this collaboration to continue to foster increases in the speed, accuracy and applicability of methods based on pan-genome graphs in the years ahead.

<!-- Benefits of de novo assemblies -->
Our results suggest that constructing a graph from de novo assembly alignment instead of a VCF leads to better SV genotyping.
High quality de novo assemblies for human are becoming more and more common due to improvements in technologies like optimized mate-pair libraries[@pJAv1D8R] and long-read sequencing[@6KbgcueR].
We expect the future graphs to include information from the alignment of numerous de novo assemblies.
We are presently working on scaling our assembly-based pipeline to human-sized genome assemblies.
Another challenge is creating genome graphs that integrate assemblies with variant-based data resources.
One possible approach is to progressively align assembled contigs into variation graphs constructed from variant libraries.
Methods for doing so are still experimental.


## Conclusion

In this study, the vg toolkit was compared to existing SV genotypers across several high-quality SV catalogs.
We showed that its method of mapping reads to a variation graph leads to better SV genotyping compared to other state of the art methods.
This work introduces a flexible strategy to integrate the growing number of SVs being discovered with higher resolution technologies into a unified framework of genome inference.
This study also shows the benefit of directly utilizing de novo assemblies rather than variant catalogs to integrate SVs in genome graphs.


## Methods

### The vg call genotyping algorithm

A simple though very general variant caller has been implemented as `vg call`.
The algorithm uses read mappings to a genome graph as its source of signal.
Here it is used to genotype structural variants already present in the graph, but the same algorithm can also be used for smaller variants such as SNPs, as well as making de-novo calls.
The algorithm is as follows:

1. The average read support for each node and edge, adjusted for mapping and base quality, is computed. 
The graph can optionally be augmented to include new variation from the reads using a minimum support cutoff.
1. The graph is then decomposed into snarls[@xJlNnKH2]. 
Briefly, a snarl is a subgraph defined by two end nodes, where cutting the graph at these nodes disconnects the subgraph from the rest of the graph.
Snarls can be nested inside other snarls, and this nesting hierarchy forms a forest.
As proposed in Paten et al.[@xJlNnKH2], we use the snarl decomposition as a structure for identifying variants in a graph.
1. Root-level snarls from the decomposition are considered independently and in parallel. 
Only snarls whose two ends lie on a reference (i.e. chromosome) path are considered as the VCF format used for output requires reference positions. 
The following steps are performed on each root snarl. 
    1. A set of paths between the snarls end nodes are computed using a heuristic search that enumerates paths until all nodes and edges in the snarl are contained in at least one path.
    1. The paths are ranked according to their average support from the reads.
    1. A genotype is determined using the relative support of the best paths, as well as the background read depth. The same logic is used for all types of variation, each of which can be expressed simply as a path in the graph.
    1. The VCF variants are derived from the paths.

### toil-vg

toil-vg is a set of Python scripts for simplifying vg tasks such as graph construction, read mapping and SV genotyping.
It uses the Toil workflow engine [@faeC2cx0] to seamlessly run pipelines locally, on clusters, or on the cloud.
All variation graph analysis in this report used toil-vg, with the exact commands available at [github.com/vgteam/sv-genotyping-paper](https://github.com/vgteam/sv-genotyping-paper).
The principal toil-vg commands used are described below.

#### toil-vg construct

toil-vg construct automates graph construction and indexing following the best practices put forth by the vg community.
Graph construction is parallelized across different sequences from the reference FASTA, and different whole-genome indexes are created side by side when possible.
Phasing information from the input VCF can be used when available to preserve haplotypes in the GCSA2 pruning step, as well as to extract haploid sequences to simulate from.

#### toil-vg map

toil-vg map splits the input reads into batches, maps each batch in parallel, and merges the result.

#### toil-vg call

Due to the high memory requirements of the current implementation of vg call, toil-vg call splits the input graph into 2.5Mb overlapping chunks along the reference path.
Each chunk is called independently in parallel and the results are concatenated into the output VCF. 

#### toil-vg sveval

toil-vg seval evaluates the SV calls relative to a truth set.
The variants are first normalized with `bcftools norm` (1.9) to ensure consistent representation between called variants and baseline variants[@LAG2q9WK].
We then implemented an overlap-based strategy to compare SVs and compute evaluation metrics (sveval R package: [https://github.com/jmonlong/sveval](https://github.com/jmonlong/sveval)).

For deletions and inversions, we begin by computing the overlaps between the SVs in the call set and the truth set.
For each variant we then compute the proportion of its region that is covered by a variant in the other set, considering only variants overlapping with at least 10% reciprocal overlap.
If this coverage proportion is higher than 50%, the variant is considered *covered*.
True positives are covered variants from the call set (when computing the precision) or the truth set (when computing the recall).
Variants from the call set are considered false positives if they are not covered by the truth set.
Conversely, variants from the truth set are considered false negatives if they are not covered by the call set.

For insertions, we select pairs of insertions that are located no farther than 20 bp from each other.
We then align the inserted sequences using a Smith-Waterman alignment.
For each insertion we compute the proportion of its inserted sequence that aligns a matched variant in the other set.
If this proportion is at least 50% the insertions are considered covered.
Covering relationships are used to define true positives, false positives, and false negatives the same way as for deletions and insertions.

sveval accepts VCF files with symbolic or explicit representation of the SVs.
If the explicit representation is used, multi-allelic variants are split and their sequences right-trimmed.
When using the explicit representation and when the REF and ALT sequences are longer than 10 bp, the reverse-complement of the ALT sequence is aligned to the REF sequence to identify potential inversions.
If more than 80% of the sequence aligns, it is classified as an inversion.

We assess both the ability to predict the presence of an SV as well as the full genotype.
For the *presence* evaluation, both heterozygous and homozygous alternate SVs are compared jointly using the approach described above.
To compute genotype-level metrics, the heterozygous and homozygous SVs are compared separately.
Before splitting the variants by genotype, consecutive heterozygous variants are first merged if located at less that 20 bp from each other.
Pairs of heterozygous variants with reciprocal overlap of at least 80% are also merged into a homozygous ALT variant before splitting variants by genotype.

### Other SV genotypers

#### BayesTyper (v1.5 beta 62888d6)

Where not specified otherwise BayesTyper was run as follows.
Raw reads were mapped to the reference genome using `bwa mem` (0.7.17).
GATK[@NCr4QkOg] (3.8) and Platypus[@1DYmkalz4] (0.8.1.1) were run on the mapped reads to call SNVs and short indels (<50bp) needed by BayesTyper for correct genotyping.
The VCFs with these variants were then normalised using `bcftools norm` (1.9) and combined with the SVs across samples using `bayesTyperTools combine` to produce the input candidate set. 
k-mers in the raw reads were counted using `kmc` (3.1.1) with a k-mer size of 55. 
A Bloom filter was constructed from these k-mers using `bayesTyperTools makeBloom`. 
Finally, variants were clustered and genotyped using `bayestyper cluster` and `bayestyper genotype`, respectively, with default parameters except `--min-genotype-posterior 0`. 
Non-PASS variants were filtered prior to evaluation using `bcftools filter`.


#### Delly (v0.7.9)

The `delly call` command was run on the reads mapped by `bwa mem`, the reference genome FASTA file, and the VCF containing the SVs to genotype (converted to their explicit representations).

#### SVTyper (v0.7.0)

The VCF containing deletions was converted to symbolic representation and passed to `svtyper` with the reads mapped by `bwa mem`.
The output VCF was converted back to explicit representation using `bayesTyperTools convertAllele` to facilitate variant normalization before evaluation.

#### SMRT-SV2 (v2.0.0 Feb 21 2019 commit adb13f2)

SMRT-SV2 was run with the "30x-4" model and min-call-depth 8 cutoff.
It was run only on VCFs created by SMRT-SV, for which the required contig BAMs were available.
The Illumina BAMs used where the same as the other methods described above.
The output VCF was converted back to explicit representation to facilitate variant normalization later.

### Simulation experiment

We simulated a synthetic genome with 1000 insertions, deletions and inversions.
Each variant was separated from the next by a buffer of at least 500 bp.
The sizes of deletions and insertions followed the distribution of SV sizes from the HGSVC catalog.
We used the same size distribution as deletions for inversions.
A VCF file was produced for three simulated samples with genotypes chosen uniformly between homozygous reference, heterozygous, and homozygous alternate.

We created another VCF file containing errors in the SV breakpoint locations.
One or both breakpoints of deletions and inversions were shifted between 1 and 10 bp.
The locations and sequences of insertions were also modified, either shifting the variants or shortening them at the flanks, again by up to 10 bp. 

Paired-end reads were simulated using `vg sim` on the graph that contained the true SVs.
Different read depths were tested: 1x, 3x, 7x, 10x, 13x, 20x.
The base qualities and sequencing errors were trained to resemble real Illumina reads from NA12878 provided by the Genome in a Bottle Consortium.

The genotypes called in each experiment (genotyping method/VCF with or without errors/sequencing depth) were compared to the true SV genotypes to compute the precision, recall and F1 score (see [toil-vg sveval](#toil-vg-sveval)).

#### Breakpoint fine-tuning using graph augmentation

vg can call variants after augmenting the graph with the read alignments to discover new variants (see [toil-vg call](#toil-vg-call)).
We tested if this approach could fine-tune the breakpoint location of SVs in the graph.
We started with the graph that contained approximate SVs (1-10 bp errors in breakpoint location) and 20x simulated reads from the simulation experiment (see [Simulation experiment](#simulation-experiment)).
The variants called after graph augmentation were compared with the true SVs.
We considered fine-tuning correct if the breakpoints matched exactly.

### HGSVC Analysis

Phased VCFs were obtained for the three Human Genome Structural Variation Consortium (HGSVC) samples from Chaisson et al.[@vQTymKCj] and combined with `bcftools merge`.
A variation graph was created and indexed using the combined VCF and the HS38D1 reference with alt loci excluded.
The phasing information was used to construct a GBWT index[@jj4JJlsg], from which the two haploid sequences from HG00514 were extracted as a graph.
Illumina read pairs with 30x coverage were simulated from these sequences using vg sim, with an error model learned from real reads from the same sample.
Still, these reads reflect an idealized situation where the breakpoints of the SVs being genotyped are exactly known a priori.
The reads were mapped to the graph, and the mappings used to genotype the SVs in the graph. 
Finally, the SV calls were compared back to the HG00514 genotypes from the HGSVC VCF.
The process was repeated with the same reads on the linear reference, using bwa-mem for mapping and Delly, SVTyper and BayesTyper for SV genotyping.

Illumina HiSeq 2500 paired end reads were downloaded from the EBI's ENA FTP site for the three samples, using Run Accessions ERR903030, ERR895347 and ERR894724 for HG00514, HG00733 and NA19240, respectively.
The graph and linear mapping and genotyping pipelines were run exactly as for the simulation, and the comparison results were aggregated across the three samples.
For BayesTyper the 3 samples were genotyped jointly.

### GIAB Analysis

Version 0.6 of the Genome in a Bottle (GIAB) SV VCF for the Ashkenazim son (HG002) was obtained from the NCBI FTP site.
Illumina reads were obtained as described in Garrison et al.[@10jxt15v0] and downsampled to 50x coverage.
These reads were used as input for vg call and the other SV genotyping pipelines described above (though with GRCh37 instead of GRCh38).
For BayesTyper, the input variant set was created by combining the GIAB SVs with SNV and indels from the same study.
Variants without a determined genotype in the GIAB call set (14649 out of 74012) were considered "false positives" as a proxy measure for precision.
These variants correspond to putative technical artifacts and parental calls not present in HG002.

### SMRT-SV2 Comparison (CHMPD and SVPOP)

The SMRT-SV2 genotyper can only be used to genotype VCFs that were created by SMRT-SV2, and therefore could not be run on the simulated, HGSVC, or GIAB call sets.
The authors shared their training and evaluation set: a pseudodiploid sample constructed from combining the haploid CHM1 and CHM13 samples (CHMPD), and a negative control (NA19240). 
The high quality of the CHM assemblies makes this set an attractive alternative to using simulated reads.
We used this two-sample pseudodiploid VCF along with the 30X read set to construct, map and genotype with vg, and also ran SMRT-SV2 genotyper with the "30x-4" model and min-call-depth 8 cutoff, and compared the two back to the original VCF.

In an effort to extend this comparison from the training data to a more realistic setting, we reran the three HGSVC samples against the SMRT-SV2 discovery VCF (SVPOP, which contains 12 additional samples in addition to the three from HGSVC) published by Audano et al.[@3NNFS6U2] using vg and SMRT-SV2 Genotyper.
The discovery VCF does not contain genotypes so we did not distinguish between heterozygous and homozygous genotypes, looking at only the presence or absence of an alt allele for each variant.

SMRT-SV2 produces some explicit *no-calls* predictions when the read coverage is too low to produce accurate genotypes.
These no-calls are considered homozygous reference in the main accuracy evaluation.
We also explored the performance of vg and SMRT-SV2 in different sets of regions (Figure {@fig:svpop-regions} and Table {@tbl:svpop-regions}):

1. Non-repeat regions, i.e. excluding segmental duplications and tandem repeats (using the respective tracks from the UCSC Genome Browser).
1. Repeat regions defined as segmental duplications and tandem repeats.
1. Regions where SMRT-SV2 could call variants.
1. Regions where SMRT-SV2 produced no-calls.

### Yeast graph analysis

For the analysis of graphs from de novo assemblies, we utilized publicly available PacBio-derived assemblies and Illumina short read sequencing datasets for 12 yeast strains from two related clades (Table {@tbl:strains}) [@7f5OKa5O].
Five strains were selected for graph contruction (two from different subclades of each clade plus the reference *S.c. S288C*): *S.c. SK1*, *S.c. YPS128*, *S.p. CBS432*, *S.p. UFRJ50816*, and *S.c. S288C*.
Two different genome graphs were constructed from the assemblies of the five selected strains.
In the following, we describe the steps for the construction of both graphs and the calling of variants.
More details and the precise commands used in our analyses can be found at [github.com/vgteam/sv-genotyping-paper](https://github.com/vgteam/sv-genotyping-paper).


| Strain      | Clade         | Included in graph |
|-------------|---------------|-------------------|
| S288C       | S. cerevisiae | ✓                 |
| SK1         | S. cerevisiae | ✓                 |
| YPS128      | S. cerevisiae | ✓                 |
| UWOPS034614 | S. cerevisiae |                   |
| Y12         | S. cerevisiae |                   |
| DBVPG6765   | S. cerevisiae |                   |
| DBVPG6044   | S. cerevisiae |                   |
| CBS432      | S. paradoxus  | ✓                 |
| UFRJ50816   | S. paradoxus  | ✓                 |
| N44         | S. paradoxus  |                   |
| UWOPS919171 | S. paradoxus  |                   |
| YPS138      | S. paradoxus  |                   |

Table: 12 yeast strains from two related clades were used in our analysis. Five strains were selected to be included in the graphs while the remaining seven were used for variant calling only. {#tbl:strains}

#### Construction of the *VCF graph*

The first graph (called the *VCF graph* throughout the paper) was constructed by adding variants onto a linear reference. 
This method requires one assembly to serve as a reference genome.
The other assemblies must be converted to variant calls relative to this reference.
The PacBio assembly of the S.c. S288C strain was chosen as the reference genome because this strain was used for the S. cerevisiae genome reference assembly.
To obtain variants for the other assemblies, three methods for SV detection from genome assemblies were combined: Assemblytics [@krO7WgVi] (commit df5361f), AsmVar (commit 5abd91a) [@oVaXIwl5] and paftools (version 2.14-r883) [@172cJaw4Q].
The union of variants detected by the three methods was produced (using bedtools [@1HWiAHnIw]), and variants with a reciprocal overlap of at least 50% were combined to avoid duplication in the union set.
These union sets of variants for each of the four selected (and non-reference) strains were merged and another deduplication step was applied to combine variants with a reciprocal overlap of at least 90%.
We then used vg construct to build the *VCF graph* with the total set of variants and the linear reference genome.

#### Construction of the *cactus graph*

The second graph (called the *cactus graph* throughout the paper) was constructed from a whole genome alignment between the assemblies.
First, the repeat-masked PacBio-assemblies of the five selected strains were aligned with our Cactus tool [@1FgS53pXi].
Cactus requires a phylogenetic tree of the strains which was estimated using Mash (version 2.1) [@mH9pzoIn] and PHYLIP (version 3.695) [@tIvRXd6o].
Subsequently, the output file in HAL format was converted to a variant graph with hal2vg ([https://github.com/ComparativeGenomicsToolkit/hal2vg](https://github.com/ComparativeGenomicsToolkit/hal2vg)).

#### Calling and genotyping of SVs

Prior to variant calling, the Illumina short reads of all 12 yeast strains were mapped to both graphs using `vg map`.
The fractions of reads mapped with specific properties were measured using `vg view` and the JSON processor `jq`.
Then, `toil-vg call` (commit be8b6da) was used to call variants.
Thus, a separate variant call set was obtained for each of the strains on both graphs.
To evaluate the callsets, a sample graph (i.e. a graph representation of the callset) was generated for each callset using `vg construct` and `vg mod` on the reference assembly *S.c. S288C* and the callset.
Subsequently, short reads from the respective strains were mapped to each sample graph using `vg map`.
The resulting alignments were analyzed with `vg view` and `jq`.


## Supplementary Material {.page_break_before}

### Supplementary Tables

| Experiment      | Method     | Type | Precision     | Recall        | F1            |
|:----------------|:-----------|:-----|:--------------|:--------------|:--------------|
| Simulated reads | vg         | INS  | 0.795 (0.885) | 0.796 (0.883) | 0.795 (0.884) |
|                 |            | DEL  | 0.869 (0.971) | 0.771 (0.92)  | 0.817 (0.945) |
|                 | BayesTyper | INS  | 0.91 (0.935)  | 0.835 (0.9)   | 0.871 (0.917) |
|                 |            | DEL  | 0.898 (0.981) | 0.806 (0.929) | 0.849 (0.954) |
|                 | SVTyper    | DEL  | 0.809 (0.876) | 0.328 (0.754) | 0.467 (0.81)  |
|                 | Delly      | INS  | 0.767 (0.866) | 0.093 (0.225) | 0.166 (0.358) |
|                 |            | DEL  | 0.696 (0.903) | 0.707 (0.846) | 0.701 (0.874) |
| Real reads      | vg         | INS  | 0.431 (0.683) | 0.541 (0.726) | 0.48 (0.704)  |
|                 |            | DEL  | 0.65 (0.886)  | 0.519 (0.708) | 0.577 (0.787) |
|                 | BayesTyper | INS  | 0.601 (0.747) | 0.254 (0.433) | 0.357 (0.549) |
|                 |            | DEL  | 0.627 (0.91)  | 0.325 (0.381) | 0.428 (0.537) |
|                 | SVTyper    | DEL  | 0.661 (0.733) | 0.236 (0.551) | 0.348 (0.629) |
|                 | Delly      | INS  | 0.516 (0.621) | 0.068 (0.176) | 0.12 (0.275)  |
|                 |            | DEL  | 0.55 (0.838)  | 0.445 (0.547) | 0.492 (0.662) |

Table: Genotyping evaluation on the HGSVC dataset. Precision, recall and F1 score for the call set with the best F1 score. The numbers in parentheses corresponds to the results in non-repeat regions. {#tbl:hgsvc tag="S1"}

---

| Method     | Type | Precision     | Recall        | F1            |
|:-----------|:-----|:--------------|:--------------|:--------------|
| vg         | INS  | 0.658 (0.774) | 0.646 (0.735) | 0.652 (0.754) |
|            | DEL  | 0.68 (0.768)  | 0.643 (0.735) | 0.661 (0.751) |
| BayesTyper | INS  | 0.776 (0.879) | 0.286 (0.379) | 0.418 (0.53)  |
|            | DEL  | 0.808 (0.886) | 0.512 (0.696) | 0.627 (0.779) |
| SVTyper    | DEL  | 0.742 (0.818) | 0.342 (0.496) | 0.468 (0.618) |
| Delly      | INS  | 0.822 (0.894) | 0.177 (0.268) | 0.291 (0.412) |
|            | DEL  | 0.722 (0.822) | 0.645 (0.768) | 0.681 (0.794) |

Table: Genotyping evaluation on the Genome in a Bottle dataset. Precision, recall and F1 score for the call set with the best F1 score. The numbers in parentheses corresponds to the results in non-repeat regions. {#tbl:giab tag="S2"}

---


| Method   | Region     | Type | Precision | Recall |    F1 |
|:---------|:-----------|:-----|----------:|-------:|------:|
| vg       | all        | INS  |     0.665 |  0.661 | 0.663 |
|          |            | DEL  |     0.688 |  0.500 | 0.579 |
|          | non-repeat | INS  |     0.806 |  0.784 | 0.795 |
|          |            | DEL  |     0.869 |  0.762 | 0.812 |
| SMRT-SV2 | all        | INS  |     0.757 |  0.536 | 0.628 |
|          |            | DEL  |     0.848 |  0.630 | 0.723 |
|          | non-repeat | INS  |     0.880 |  0.680 | 0.767 |
|          |            | DEL  |     0.971 |  0.824 | 0.891 |

Table: Genotyping evaluation on the pseudo-diploid genome built from CHM cell lines in Audano et al.[@3NNFS6U2]. {#tbl:chmpd tag="S3"}

---

| Method   | Region     | Type |    TP |    FP |    FN | Precision | Recall |    F1 |
|:---------|:-----------|:-----|------:|------:|------:|----------:|-------:|------:|
| vg       | all        | INS  | 25838 | 22042 | 15772 |     0.540 |  0.621 | 0.577 |
|          |            | DEL  | 14545 |  6824 | 15425 |     0.681 |  0.485 | 0.567 |
|          |            | INV  |    27 |    26 |   173 |     0.509 |  0.135 | 0.213 |
|          | non-repeat | INS  |  8051 |  3258 |  1817 |     0.712 |  0.816 | 0.760 |
|          |            | DEL  |  3769 |   623 |   818 |     0.858 |  0.822 | 0.840 |
|          |            | INV  |    19 |    12 |    75 |     0.613 |  0.202 | 0.304 |
| SMRT-SV2 | all        | INS  | 16270 | 26031 | 25340 |     0.385 |  0.391 | 0.388 |
|          |            | DEL  | 11793 | 10106 | 18177 |     0.539 |  0.393 | 0.455 |
|          | non-repeat | INS  |  4483 |  4659 |  5385 |     0.490 |  0.454 | 0.472 |
|          |            | DEL  |  2928 |   930 |  1659 |     0.759 |  0.638 | 0.693 |

Table: Calling evaluation on the SVPOP dataset. Combined results for the HG00514, HG00733 and NA19240 individuals, 3 of the 15 individuals used to generate the high-quality SV catalog in Audano et al.[@3NNFS6U2]. {#tbl:svpop tag="S4"}

---

| Method   | Region                | Type |   TP |   FP |   FN | Precision | Recall |    F1 |
|:---------|:----------------------|:-----|-----:|-----:|-----:|----------:|-------:|------:|
| vg       | all                   | INS  | 8618 | 7237 | 5416 |     0.546 |  0.614 | 0.578 |
|          |                       | DEL  | 4762 | 2048 | 5145 |     0.696 |  0.481 | 0.569 |
|          |                       | INV  |   11 |    8 |   54 |     0.579 |  0.169 | 0.262 |
|          | repeat                | INS  | 6176 | 6923 | 4678 |     0.475 |  0.569 | 0.518 |
|          |                       | DEL  | 2428 | 1701 | 4542 |     0.584 |  0.348 | 0.436 |
|          |                       | INV  |    1 |    1 |    6 |     0.500 |  0.143 | 0.222 |
|          | non-repeat            | INS  | 2677 |  987 |  514 |     0.731 |  0.839 | 0.781 |
|          |                       | DEL  | 1180 |  176 |  321 |     0.869 |  0.786 | 0.825 |
|          |                       | INV  |    7 |    4 |   20 |     0.636 |  0.259 | 0.368 |
|          | called in SMRT-SV     | INS  | 3410 | 3789 | 2108 |     0.478 |  0.618 | 0.539 |
|          |                       | DEL  | 2544 | 1092 | 1518 |     0.699 |  0.626 | 0.661 |
|          |                       | INV  |    8 |    8 |   52 |     0.500 |  0.133 | 0.210 |
|          | not called in SMRT-SV | INS  | 4838 |  542 | 3678 |     0.899 |  0.568 | 0.696 |
|          |                       | DEL  | 2034 |   26 | 3723 |     0.987 |  0.353 | 0.520 |
| SMRT-SV2 | all                   | INS  | 5245 | 8563 | 8789 |     0.394 |  0.374 | 0.384 |
|          |                       | DEL  | 3741 | 3382 | 6166 |     0.533 |  0.378 | 0.442 |
|          | repeat                | INS  | 3848 | 7125 | 7006 |     0.368 |  0.354 | 0.361 |
|          |                       | DEL  | 1990 | 2832 | 4980 |     0.426 |  0.286 | 0.342 |
|          | non-repeat            | INS  | 1396 | 1468 | 1795 |     0.493 |  0.438 | 0.464 |
|          |                       | DEL  |  901 |  308 |  600 |     0.745 |  0.600 | 0.665 |
|          | called in SMRT-SV     | INS  | 4343 | 5595 | 1175 |     0.445 |  0.787 | 0.569 |
|          |                       | DEL  | 3227 | 2451 |  835 |     0.573 |  0.794 | 0.666 |
|          | not called in SMRT-SV | INS  |  116 |  109 | 8400 |     0.551 |  0.014 | 0.026 |
|          |                       | DEL  |  206 |   16 | 5551 |     0.911 |  0.036 | 0.069 |

Table: Calling evaluation on the SVPOP dataset in different sets of regions for the HG5014 individual. {#tbl:svpop-regions tag="S5"}

---

| SV type | Error type   | Breakpoint | Variant | Proportion | Mean size (bp) | Mean error (bp) |
|:--------|:-------------|:-----------|--------:|-----------:|---------------:|----------------:|
| DEL     | one end      | incorrect  |     220 |      0.219 |        422.655 |           6.095 |
|         |              | fine-tuned |     784 |      0.781 |        670.518 |           5.430 |
|         | both ends    | incorrect  |     811 |      0.814 |        826.070 |           6.275 |
|         |              | fine-tuned |     185 |      0.186 |        586.676 |           2.232 |
| INS     | location/seq | incorrect  |     123 |      0.062 |        428.724 |           6.667 |
|         |              | fine-tuned |    1877 |      0.938 |        440.043 |           6.439 |
| INV     | one end      | incorrect  |     868 |      0.835 |        762.673 |           5.161 |
|         |              | fine-tuned |     172 |      0.165 |        130.244 |           5.884 |
|         | both ends    | incorrect  |     950 |      0.992 |        556.274 |           5.624 |
|         |              | fine-tuned |       8 |      0.008 |        200.000 |           1.375 |

Table: Breakpoint fine-tuning using graph augmentation from the read alignment. 
For deletions and inversions, either one or both breakpoints were shifted to introduce errors in the input VCF. 
For insertions, the insertion location and sequence contained errors.
In all cases, the errors affected 1-10 bp.
{#tbl:simerror-bkpt tag="S6"}

### Supplementary Figures

![**Genotyping evaluation on the HGSVC dataset using simulated reads.**](images/hgsvc-sim-geno.png){#fig:hgsvc-sim-geno tag="S1"}

![**Calling evaluation on the HGSVC dataset using simulated reads.**](images/hgsvc-sim.png){#fig:hgsvc-sim tag="S2"}

![**Genotyping evaluation on the HGSVC dataset using real reads.** Combined results across the HG00514, HG00733 and NA19240.](images/hgsvc-real-geno.png){#fig:hgsvc-real-geno tag="S3"}

![**Calling evaluation on the HGSVC dataset using real reads.** Combined results across the HG00514, HG00733 and NA19240.](images/hgsvc-real.png){#fig:hgsvc-real tag="S4"}

![**Genotyping evaluation on the Genome in a Bottle dataset.** Predicted genotypes on HG002 were compared to the high-quality SVs from this same individual.](images/giab5-geno.png){#fig:giab-geno tag="S5"}

![**Calling evaluation on the Genome in a Bottle dataset.** Calls on HG002 were compared to the high-quality SVs from this same individual.](images/giab5.png){#fig:giab tag="S6"}

![**Genotyping evaluation on the CHM pseudo-diploid dataset.** The pseudo-diploid genome was built from CHM cell lines and used to train SMRT-SV2 in Audano et al.[@3NNFS6U2]](images/chmpd-geno.png){#fig:chmpd-geno tag="S7"}

![**Calling evaluation on the CHM pseudo-diploid dataset.** The pseudo-diploid genome was built from CHM cell lines and used to train SMRT-SV2 in Audano et al.[@3NNFS6U2]](images/chmpd.png){#fig:chmpd tag="S8"}

![**Calling evaluation on the SVPOP dataset.** Combined results across the HG00514, HG00733 and NA19240.](images/svpop.png){#fig:svpop tag="S9"}

![**Evaluation across different sets of regions in HG00514 (SVPOP dataset)**. Calling evaluation.](images/svpop-regions.png){#fig:svpop-regions tag="S10"}


![**Breakpoint fine-tuning using augmentation through "vg call".**
For deletions and inversions, either one or both breakpoints were shifted to introduce errors in the input VCF. 
For insertions, the insertion location and sequence contained errors.
a) Proportion of variant for which breakpoints could be fine-tuned. 
b) Distribution of the amount of errors that could be corrected or not.
c) Distribution of the size of the variants whose breakpoints could be fine-tuned or not.
](images/simerror-bkpt-finetuning-vgcall.png){#fig:simerror-bkpt tag="S11"}

![**Mapping comparison.**
Short reads from all 12 yeast strains were aligned to both graphs.
The fraction of reads mapped to the cactus graph (y-axis) and the VCF graph (x-axis) are compared.
a) Stratified by percent identity threshold.
b) Stratified by mapping quality threshold.
Colors and shapes represent the 12 strains and two clades, respectively.
Transparency indicates whether the strain was included or excluded in the graphs.
](images/panel3.png){#fig:panel3 tag="S12"}

![**Mapping comparison on graphs of all 12 strains.**
Short reads from all 12 yeast strains were aligned to both graphs. The fraction of reads mapped to the *cactus graph* (y-axis) and the *VCF graph* (x-axis) are compared.
a) Stratified by percent identity threshold.
b) Stratified by mapping quality threshold.
Colors and shapes represent the 12 strains and two clades, respectively.
](images/panel5.png){#fig:panel5 tag="S13"}

![**SV genotyping comparison on graphs of all 12 strains.**
Short reads from all 11 non-reference yeast strains were used to genotype SVs contained in both graphs. Subsequently, sample graphs were generated from the resulting SV callsets. The short reads were again aligned to the sample graphs and the quality of the alignments was used to ascertain genotyping performance.
a) Average mapping quality of short reads aligned to the sample graphs derived from *cactus graph* (y-axis) and *VCF graph* (x-axis).
b) Average mapping identity of short reads aligned to the sample graphs derived from *cactus graph* (y-axis) and *VCF graph* (x-axis). 
Colors and shapes represent the 11 non-reference strains and two clades, respectively.
](images/panel6.png){#fig:panel6 tag="S14"}

### Supplementary Information

#### Variation graph and structural variation

A variation graph encodes DNA sequence in its nodes.
Such graphs are bidirected, in that we distinguish between edges incident on the starts of nodes from those incident on their ends.
A path in such a graph is an  ordered list of nodes where each is associated with an orientation.
If a path walks from, for example, node A in the forward orientation to node B in the reverse orientation, then an edge must exist from the end of node A to the end of node B.
Concatenating the sequences on each node in the path, taking the reverse complement when the node is visited in reverse orientation, produces a DNA sequence. 
Accordingly, variation graphs are constructed so as to encode haplotype sequences as walks through the graph.
Variation between sequences shows up as bubbles in the graph [@xJlNnKH2].
Figure {@fig:vg-sv-cartoon} shows how a graph with a SNP and an indel can be extended to contain more complex SVs.


#### Breakpoint fine-tuning

In addition to genotyping, vg can use an augmentation step to modify the graph based on the read alignment and discover novel variants.
On the simulated SVs from Figure {@fig:1}b, this approach was able to correct many of the 1-10 bp breakpoint errors that were added to the input VCF.
The breakpoints were accurately fine-tuned for 93.8% of the insertions (Figure {@fig:simerror-bkpt}a and Table {@tbl:simerror-bkpt}).
For deletions, 78.1% of the variants were corrected when only one breakpoint had an error.
In situations where both breakpoints of the deletions were incorrect, only 18.6% were corrected through graph augmentation, and only when the amount of error was small (Figure {@fig:simerror-bkpt}b).
The breakpoints of less than 20% of the inversions could be corrected.
Across all SV types, the size of the variant didn't affect the ability to fine-tune the breakpoints through graph augmentation (Figure {@fig:simerror-bkpt}c).

#### Mappability comparison between yeast graphs

In order to elucidate whether the *cactus graph* represents the sequence diversity among the yeast strains better than the *VCF graph*, we mapped Illumina short reads to both graphs using `vg map`.
Generally, more reads mapped to the *cactus graph* with high identity (Figure {@fig:panel3}a) and high mapping quality (Figure {@fig:panel3}b) than to the *VCF graph*.
The *VCF graph* exhibited higher mappability only on the reference strain *S.c. S288C* with a marginal difference.
The benefit of using the *cactus graph* is largest for strains in the *S. paradoxus* clade and smaller for strains in the *S. cerevisiae* clade.
We found that the genetic distance to the reference strain (as estimated using Mash v2.1 [@mH9pzoIn]) correlated with the increase in confidently mapped reads (mapping quality >= 60) between the *cactus graph* and the *VCF graph* (Spearman's rank correlation, p-value=3.993e-06).
These results suggest that the improvement in mappability is not driven by the higher sequence content in the *cactus graph* alone (15.4 Mb compared to 12.4 Mb in the *VCF graph*).
Instead, an explanation could be the construction of the *VCF graph* from a comprehensive but still limited list of variants and the lack of SNPs and small Indels in this list.
Consequently, substantially fewer reads mapped to the *VCF graph* with perfect identity (Figure {@fig:panel3}a, percent identity threshold = 100%) than to the *cactus graph*.
The latter has the advantage of implicitly incorporating variants of all types and sizes from the de novo assemblies.
As a consequence, the *cactus graph* captures the genetic makeup of each strain more comprehensively and enables more reads to be mapped.

Interestingly, our measurements did not show a substantial difference between strains that were used to construct the graph and the other strains. 
Only the number of alignments with perfect identity is substantially lower for the strains that were not included in the creation of the graphs (Figure {@fig:panel3}a). 
For a direct comparison, see Figure {@fig:panel5} which shows results of the same experiment on graphs generated from all 12 strains.


## References {.page_break_before}

<!-- Explicitly insert bibliography here -->
<div id="refs"></div>
