## Results

### Structural variation in vg

In addition to SNV and short indels, vg can handle large deletions, insertions and inversions (Figure {@fig:1}a).
As a proof-of-concept we simulated genomes and different types of SVs with a size distribution matching real SVs[@tag:hgsvc].
We compared vg against SVTyper, Delly and BayesTyper across different level of sequencing depth.
Some errors were also added at the breakpoints to investigate their effect on genotyping (see [Methods](#methods)).
The results are shown in Figure {@fig:1}b.
When using the correct breakpoints, vg tied with Delly as the best genotyper for deletions, and with BayesTyper as the best genotyper for insertions.
For inversions, vg was the second best genotyper after BayesTyper.
The differences between the methods were the most visible at lower sequencing depth. 
In the presence of 1-10 bp errors in the breakpoint location, the performance of Delly and BayesTyper dropped significantly.
The dramatic drop for BayesTyper can be explained by its khmer-based approach that requires exact SV definition.
In contrast, vg was only slightly affected by the presence of errors in the input VCF (Figure {@fig:1}b).
For vg, the F1 scores for all SV types decreased no more than of 0.07 point.
Overall, these results show that vg is capable of genotyping SVs and is robust to errors in the input VCF.

![**Structural variation in vg.** 
a) Adding large deletions and insertions in a variation graph. 
b) Simulation experiment. For each experiment (method, depth and input VCF with/without errors), the maximum F1 was picked when using different quality thresholds, and is reported on the y-axis.
](images/panel1.png){#fig:1}

### HGSVC dataset

The Human Genome Structural Variation Consoritum (HGSVC) generated a high-quality SV catalog of three samples, obtained using a consensus from different sequencing, phasing and variant caling technologies[@tag:hgsvc]. 
The three samples come from different human populations: a han Chinese individual (HG00514), a Puerto-Rican individual (HG00733), and a Yoruban Nigerian individual (NA19240).
These SVs were used to construct a graph with vg and as input for the other genotypers.
SVs were genotyped from short reads and compared with the original catalog (see [Methods](#methods)).

First, by simulating reads for HG00514, we compared the different methods in the ideal situation where the SV catalog is correct and matches exactly the SVs supported by the reads.
While vg outperformed Delly and SVTyper, BayesTyper showed the best F1 score and precision-recall trade-off (Figures {@fig:2} and {@fig:hgsvc-sim-geno}, Table {@tbl:hgsvc}).
When restricting the comparisons to regions not identified as tandem repeats or segmental duplications, the genotyping predictions were significantly better for all methods, with vg almost as good as BayesTyper on deletions (F1 of 0.944 vs 0.955).
We observed similar results when evaluating the absence/presence of a SV instead of the exact genotype (Figures {@fig:2} and {@fig:hgsvc-sim}).
Overall, both graph-based methods, vg and BayesTyper, outperformed the two other methods tested.

We then repeated the analysis using real Illumina reads from HG00514, to benchmark the methods on a more realistic experiment.
Here vg clearly outperformed other approach, most likely because of its graph-based strategy and robustness to errors in the SV catalog (Figures {@fig:2} and  {@fig:hgsvc-real-geno}).
In non-repeat regions and across the whole genome, the F1 scores and precision-recall curves were higher for vg compared to other methods. 
For example, for deletions in non-repeat regions, the F1 score for vg was 0.801 while the second best method, Delly, had a F1 score of 0.692.
We observed similar results when evaluating the absence/presence of a SV instead of the exact genotype (Figures {@fig:2} and  {@fig:hgsvc-real}).

![**Structural variants from the HGSVC and Genome in a Bottle datasets**. 
HGSVC: Simulated and real reads were used to genotype SVs and compared with the high-quality calls from Chaisson et al.[@tag:hgsvc].
Reads were simulated from the HG00514 individual.
Using real reads, the three HG00514, HG00733, and NA19240 individuals were tested.
GiaB: Real reads from the HG002 individual were used to genotype SVs and compared with the high-quality calls from the Genome in a Bottle consortium.[@doi:10.1038/sdata.2016.25;@doi:10.1101/281006].
Maximum F1 score for each method (color), across the whole genome or focusing on non-repeat regions (x-axis). 
The calling and genotyping evaluation are shown with different shades.
](images/hgsvc-giab-best-f1.png){#fig:2}

### Other long-read datasets

The Genome in a Bottle (GiaB) consortium is currently producing a high-quality SV catalog for a Ashkenazim individual (HG002)[@doi:10.1038/sdata.2016.25;@doi:10.1101/281006].
Dozens of SV callers and datasets from short, long and linked reads were used to produce this set of SVs.
vg performed similarly on this dataset than in the HGSVC dataset, with a F1 score of 0.75 for both insertions and deletions in non-repeat regions (Figures {@fig:2}, {@fig:giab-geno} and {@fig:giab}, and Table {@tbl:giab}).
As before, other methods produced lower F1 scores in most cases, although Delly and BayesTyper predicted better genotype for deletions in non-repeat regions.

A recent study by Audano et al. generated a SV catalog using long-read sequencing across 15 individuals [@tag:audano2019].
These variants were then genotyped from short reads across 440 individuals using SMRT-SV2, a machine-learning genotyper implemented for this study.
We first called SVs from the pseudo-diploid genome and reads used to train SMRT-SV2 and constructed by merging datasets from two haploid cell lines[@tag:audano2019].
The absence/presence predictions from vg were systematically better than SMRT-SV2 for both SV types but SMRT-SV2 produced better genotypes for deletions (see Figures {@fig:chmpd-chmpd}, {@fig:chmpd-geno} and {@fig:chmpd}, and Table {@tbl:chmpd}). 
Using publicly available Illumina reads, we then genotyped SVs in 3 of the 15 individuals that were used for discovery in Audano et al.[@tag:audano2019].
Compared to SMRT-SV2, vg had a better precision-recall curve and a higher F1 for both insertions and deletions (Figures {@fig:chmpd-svpop} and {@fig:svpop}, and Table {@tbl:svpop}).
Of note, Audano et al. had identified 217 sequence-resolved inversions.
vg correctly predicted the presence of around 14% of the inversions present in the three samples (Table {@tbl:svpop}).
Inversions are often complex, harboring additional variation that makes their characterization and genotyping challenging.

![**Structural variants from Audano et al.[@tag:audano2019]**.
The pseudo-diploid genome built from CHM cell lines was used originally used to train SMRT-SV2 in Audano et al.[@tag:audano2019].
The SVPOP panel shows the combined results for the HG5014, HG00733 and NA19240 individuals, 3 of the 15 individuals used to generate the high-quality SV catalog in Audano et al.[@tag:audano2019].
Maximum F1 score for each method (color), across the whole genome or focusing on non-repeat regions (x-axis). 
The calling and genotyping evaluation are shown with different shades.
](images/chmpd-svpop-best-f1.png){#fig:chmpd-svpop}

 
### Genotyping SV using vg and de novo assemblies

We investigated whether genome graphs derived from genome-genome alignments yield advantages for SV genotyping.
To this end, we analyzed public sequencing datasets for 12 yeast strains from two clades (S. cerevisiae and S. paradoxus) [@doi:10.1038/ng.3847].
From these datasets, we generated two different types of genome graphs.
The first graph type (in the following called *construct graph*) was created from a linear reference genome of the S.c. S288C strain and a set of SVs relative to this reference strain in VCF format.
We compiled the SV set using the output of three methods for SV detection from genome assemblies: Assemblytics [@doi:10.1093/bioinformatics/btw369], AsmVar [@doi:10.1186/s13742-015-0103-4] and paftools [@doi:10.1093/bioinformatics/bty191].
All three methods were run to detect SVs between the reference strain S.c. S288C and each of the other 11 strains.
Merging the results from the three methods and the 11 strains provided us with a high-sensitivity set of SVs occuring in the two yeast clades.
We used this set to construct the *construct graph*.
The second graph (in the following called *cactus graph*) was derived from a multiple genome alignment of all 12 strains using our Cactus tool [@doi:10.1101/gr.123356.111].
While the *construct graph* is still mainly linear and highly dependent on the reference genome, the cactus graph is completely unbiased in that regard.

![**Mapping comparison.** 
The fraction of reads mapped to the cactus graph (y-axis) and the construct graph (x-axis) are compared.
a) Stratified by mapping quality threshold.
b) Stratified by percent identity threshold.
](images/panel3.png){#fig:3}

In a first step, we tested our hypothesis that the *cactus graph* has higher mappability due to its better representation of sequence diversity among the yeast strains.
Figure {@fig:3}a shows the fraction of Illumina reads from the 12 strains that was mapped with a mapping quality above a certain threshold to the *cactus graph* and to the *construct graph*.
Generally, more reads were mapped to the *cactus graph* than to the *construct graph* regardless of the chosen mapping quality threshold.
Only for the reference strain S.c. S288C, both graphs exhibited similar mappability.
This suggests that not the higher sequence content in the *cactus graph*  alone (XX Mb compared to XX Mb in the *construct graph*) drives the improvement in mappability.
Instead, our measurements suggest that genetic distance to the reference strain increases the advantage of the *cactus graph* over the *construct graph*.
Consequently. the benefit of the *cactus graph* is largest for strains in the S. paradoxus clade and smaller for reads from strains in the S. cerevisiae clade.

When we explored the mapping identity of the short reads on the graphs, we observed a similar trend (see Figure {@fig:3}b).
For strains in the S. paradoxus clade, the *cactus graph* enabled substantially more mappings with high percent identity than the *construct graph*.
With strains in the S. cerevisiae clade, the difference was smaller, at least for a percent identity threshold up to 90%.
When comparing read fractions with perfect identity (i.e. percent identity threshold = 100%), the *cactus graph* clearly outperforms the *construct graph* on 11 out of 12 samples.
The only exception again is the reference strain S288C.

![**SV genotyping comparison.** 
a) Average mapping quality of short reads mapped to the *cactus graph* (y-axis) and *construct graph* (x-axis).
b) Average mapping identity of short reads mapped to the *cactus graph* (y-axis) and *construct graph* (x-axis). 
Colors and shapes represent the 11 non-reference strains and two clades, respectively
](images/panel4.png){#fig:4}

Next, we compared the SV genotype performance of both graphs.
We mapped short reads from the 11 non-reference strains to both graphs and called variants using vg's variant calling module.
To compare the callsets from both graphs, we generated a sample graph for each callset using the reference genome and the callset.
Each sample graph is a graph representation of the respective callset.
If a given callset is correct, we would expect that reads from the same sample can be mapped confidently and with high identity to the corresponding sample graph.
Therefore, we compared the average mapping identity of the short reads on both types of sample graphs (see Figure {@fig:4}b).
Similar to the results of our mapping analysis above, the *cactus graph* clearly outperformed the *construct graph* for strains in the S. paradoxus clade.
With strains in the S. cerevisiae clade, both graphs were on a par.

This trend was confirmed when we looked at two our measures, average mapping quality and average alignment score (see Figures {@fig:4}a and {@fig:geno-comp-score}).

