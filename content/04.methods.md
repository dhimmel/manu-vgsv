## Methods

### Toil-vg

Toil-vg is a set of Python scripts for simplifying vg tasks such as graph construction, read mapping and SV genotyping.  It uses the Toil workflow engine [@tag:toil] to seamlessly run pipelines locally, on clusters or on the cloud.  All variation graph analysis in this report was done using toil-vg, with the exact commands available [here](https://github.com/glennhickey/hgsvc) [todo: get everything in one place with reasonable docs].  The principal toil-vg commands used are described below.

#### Toil-vg construct

Toil-vg construct automates graph construction and indexing following the best practices put forth by the vg community.
Graph construction is parallelized across different sequences from the reference fasta, and different whole-genome indexes are created side by side when possible.
Phasing information from the input VCF can be used when available to preserve haplotypes in the GCSA2 pruning step, as well as to extract haploid sequences to simulate from.

#### Toil-vg map

Toil-vg map splits the input reads into batches, maps each batch in parallel, then merges the result.

#### Toil-vg call

A simple though very general variant caller has been implemented as `vg call`.
Here it is used to genotype structural variants already present in the graph, but the same algorithm can also be used for smaller variants such as SNPs, as well as making de-novo calls.
The algorithm is as follows:

1. The average read support for each node and edge, adjusted for mapping and base quality, is computed. 
The graph can optionally be augmented to include new variation from the reads.
1. The graph is then decomposed into snarls. 
Briefly, a snarl is a subgraph defined by two end nodes, where cutting the graph at these nodes disconnects the snarl from the rest of the graph.  (todo: work on way to define this without getting into bidirected graphs, or is that a lost cause?). 
Snarls can be nested inside other snarls, and this nesting hierarchy forms a forest (todo: I don't think chains get used anywhere in vg call so we can ignore here). 
The snarl decomposition is a fundamental structure for identifying variants in a graph and were formally defined by Paten et al.[@tag:snarls], along with an algorithm to identify them.
1. Root-level snarls from the decomposition are considered independently and in parallel. 
Only snarls whose two ends lie on a reference (i.e. chromosome) path are considered as the VCF format used for output requires reference positions. 
The following steps are performed on each root snarl. 
    1. A set of paths between the snarls end nodes are computed. (todo, consult with Adam about writing up the RepresentativeTraversalFinder)
    1. The paths are ranked according to their average support.
    1. A genotype is determined using the relative support of the best traversals, as well as the background read depth.
    1. The VCF variants are derived from the paths.

(todo: expand and clarify these last steps.  could leave them fairly brief here and go into detail in the supplement).

Due to the high memory requirements of the current implementation of vg call, toil-vg call splits the input graph into 2.5Mb overlapping chunks along the reference path.
Each chunk is called independently in parallel and the results are concatenated into the output VCF. 

#### Toil-vg sveval

The variants are first normalized with `bcftools norm` to ensure consistent representation between called variants and baseline variants.
We then implemented an overlap-based strategy to compare SVs and compute evaluation metrics (sveval R package: [https://github.com/jmonlong/sveval](https://github.com/jmonlong/sveval)).

For deletions and inversions, the affected regions in the reference genome are overlapped and matched between the two sets of SVs.
First, we select pairs of SVs with at least 10% reciprocal overlap.
Then for each variant we compute the proportion of its region that is covered by an overlapping variant in the other set.
If this coverage proportion is higher than 50%, the variant is considered *covered*.
True positives are *covered* variants from the call set or the truth set.
False positives are variants from the call set that are not *covered*.
False negative are variants from the truth set that are not *covered*.

For insertions, we select pairs of insertions that are located no farther than 20 bp from each other.
We then align the inserted sequences using a Smith-Waterman alignment.
For each insertion we compute the proportion of its inserted sequence that aligns a matched variant in the other set.
As for deletions/inversions, this coverage proportion is used to annotate variants as true positives, false positives and false negatives.

sveval accepts VCF files with symbolic or explicit representation of the SVs.
If the explicit representation is used, multi-allelic variants are split and their sequences right-trimmed.
When inversions are considered, the reverse-complement of the ALT sequence of variants larger than 10 bp is aligned to the REF sequence and classified as an inversion if more than 80% of the sequence aligns.

We assess either the *calling* performance (absence/presence of a SV) or the *genotyping* performance.
For the *calling* evaluation, both heterozygous and homozygous alternate SVs are compared jointly using the approach described above.
To compute genotype-level metrics, the heterozygous and homozygous SVs are compared separately.
Before splitting the variants by genotype, consecutive heterozygous variants are first stitched together if located at less that 20 bp from each other.
Pairs of heterozygous variants with reciprocal overlap of at least 80% are also merged into homozygous variant before splitting variants by genotype.

### Other SV genotypers

#### BayesTyper

If not specified otherwise BayesTyper was run as follows.
Raw reads were mapped to the reference genome using `bwa mem`.
GATK and Platypus were run on the mapped reads to call SNVs and short indels (<50bp).
The VCFs with these variants and the SVs to genotype were combined and used as input for BayesTyper.
The BayesTyper genotyping pipeline started by counting the kmers in the raw reads using `kmc -k55 -ci1 -m8`.
These kmers are then passed through a Bloom filter using `bayesTyperTools makeBloom`.
Finally, variants are clustered and genotyped using `bayestyper cluster` and `bayestyper genotype --min-genotype-posterior 0`.

#### Delly

The `delly call` command was run on the reads mapped by `bwa mem`, the reference genome fasta file and the VCF containing the SVs to genotype in their explicit representation.

#### SVTyper

The VCF containing deletions was converted to symbolic representation and passed to `svtyper` with the reads mapped by `bwa mem`.
The output VCF was converted back to explicit representation using `bayesTyperTools convertAllele` to facilitate variant normalization before evaluation.

#### SMRT-SV2

SMRT-SV2 was run on VCFs generated for SMRT-SV2 with the "30x-4" model and min-call-depth 8 cutoff.
The output VCF was converted back to explicit representation, to facilitate variant normalization later.

(todo: double-check and maybe more details from Glenn)


### Simulation experiment

We simulated a synthetic genome with 1000 insertions, deletions and inversions.
Each variant was separated from the next by a buffer region of 500 bp.
The size of deletions and insertions followed the distribution of real SVs from the HGSVC catalog.
We used the same size distribution as deletions for inversions.
A VCF file was produced for three simulated samples with random genotypes (homozygous reference, heterozygous, homozygous alternate).

We created another VCF file containing errors in the SV definition.
One or both breakpoints of deletions and inversions were shifted between 1 and 10 bp.
The location and sequence of insertions were also modified, either shifted or deleted at the flanks, again by up to 10 bp. 

Paired-end reads were simulated using `vg sim` on the graph that contained the true SVs.
Different read depth were tested: 1x, 3x, 7x, 10x, 13x, 20x.
We used real Illumina reads from NA12878 provided by the Genome in a Bottle consortium to model base qualities and sequencing errors.

The different methods were tested using either the true VCF or the VCF that contained errors.
For vg, a graph was constructed from the VCF file, indexed, then used to map simulated reads and call variants using toil-vg (see [Toil-vg](#toil-vg)).
A beta version 1.5 of BayesTyper was run directly on the simulated reads and using an input VCF with SV only.
In order to run the other methods, reads were mapped to the linear reference sequence using `bwa mem` and sorted using `samtools`.
For Delly, insertions and deletions were first genotyped together using these mapped reads and the `delly call` command.
Inversions were genotyped separately using a VCF that was formatted according to Delly's preference.
SVTyper was run on the mapped reads and a VCF that was converted to symbolic variant representation.
All commands used for this analysis are available at [ANALYSIS_REPO](XXX).

The genotypes called in each experiment (method/VCF with or without errors/sequencing depth) were compared to the true SV genotypes to compute the precision, recall and F1 score (see [Toil-vg sveval](#toil-vg-sveval)).

#### Breakpoint fine-tuning using graph augmentation

vg can call variants after augmenting the graph with the read alignments to discover new variants (see [Toil-vg call](#toil-vg-call)).
We tested if this approach could fine-tune the breakpoint location of SVs in the graph.
We started with the graph that contained approximate SVs (1-10 bp errors in breakpoint location) and 20x simulated reads from the simulation experiment (see [Simulation experiment](#simulation-experiment)).
The variants called after graph augmentation were compared with the true SVs and considered fine-tuned if the breakpoints matched exactly.

### HGSVC Analysis

Phased VCFs were obtained for the three HGSVC samples from Chaisson et al.[@tag:hgsvc] and combined with `bcftools merge`.
A variation graph was created and indexed using the combined VCF and the HS38D1 reference with alt loci excluded.
The phasing information was used to construct a GBWT index, from which the two haploid sequences from HG00514 were extracted.
Illumina read pairs with 30x coverage were simulated from these sequences using vg, with an error model learned from real reads from the same sample.
Still, these reads reflect the idealized situation where the breakpoints of the SVs being genotyped are exactly known a priori.
The reads were mapped to the graph and the mappings used to genotype the SVs in the graph, which were finally compared back to the HG00514 genotypes from the HGSVC VCF.
The process was repeated with the same reads on the linear reference, using bwa-mem for mapping and Delly, SVTyper and BayesTyper for SV genotyping.

Illumina HiSeq 2500 paired end reads were downloaded from the EBI's ENA FTP site for the three samples, using Run Accessions ERR903030, ERR895347 and ERR894724 for HG00514, HG00733 and NA19240, respectively.
The graph and linear mapping and genotyping pipelines were run exactly as for the simulation, and the comparison results were aggregated across the three samples.

### GIAB Analysis

Version 0.6 of the GIAB SV VCF for the Ashkenazim son (HG002) was obtained from the NCBI FTP site.
Illumina reads downsampled to 50x coverage obtained as described in Garrison et al.[@tag:vgnbt], were used to run the vg and linear SV genotyping pipelines described above though with GRCh37 instead of 38.
Since this dataset contains only one sample, variants without a determined genotype (14649 out of 74012) were considered "false positives" as a proxy measure for precision.

### SMRT-SV2 Comparison (CHMPD and SVPOP)

The SMRT-SV2 genotyper can only be used to genotype VCFs that were created by SMRT-SV2, and therefore could not be run on our simulated, HGSVC or GIAB data.
The authors shared their training and evaluation set, a pseudodiploid sample constructed from combining the haploid CHM1 and CHM13 samples, along with a negative control (NA19240). 
The high quality of the CHM assemblies makes this set an attractive alternative to using simulated reads.
We used this two-sample pseudodiploid VCF along with the 30X read set to construct, map and genotype with vg, and also ran SMRT-SV2 genotyper with the "30x-4" model and min-call-depth 8 cutoff, and compared the two back to the original VCF.

In an effort to extend this comparison to a more realistic setting, we reran the three HGSVC samples against the SMRT-SV2 discovery VCF (which contains them in addition to 12 other samples) published by Audano et al.[@tag:audano2019] using vg and SMRT-SV2 Genotyper.
The discovery VCF does not contain genotypes so we did not distinguish between heterozygous and homozygous genotypes, looking at only the presence or absence of an alt allele for each variant.

SMRT-SV2 produces some explicit *no-calls* predictions when the read coverage is too low to produce accurate genotypes.
These no-calls are considered homozygous reference in the main evaluation.
We also explored the performance of vg and SMRT-SV2 in different sets of regions:

1. Non-repeat regions, i.e. excluding segmental duplications and tandem repeats.
1. Repeat regions defined as segmental duplications and tandem repeats.
1. Regions where SMRT-SV2 could call variants.
1. Regions where SMRT-SV2 produced no-calls.

### Yeast graph analysis

For the analysis of graphs from de novo assemblies, we utilized publicly available PacBio-derived assemblies and Illumina short read sequencing datasets for 12 yeast strains from two related clades (Table {@tbl:strains}) [@doi:10.1038/ng.3847].
Two different genome graphs were constructed from the assemblies of five selected strains (S.c. S288C, S.c. SK1, S.c. YPS128, S.p. CBS432, and S.p. UFRJ50816).
In the following, we describe the steps for the construction of both graphs and the calling of variants.
For more details and the precise commands used in our analyses, see the following GitHub repository: https://github.com/eldariont/yeast_sv.

(todo: merge all analysis code to one documented repo)

| Strain      | Clade         | Included in graph |
|-------------|---------------|-------------------|
| S288C       | S. cerevisiae | ✓                 |
| SK1         | S. cerevisiae | ✓                 |
| YPS128      | S. cerevisiae | ✓                 |
| UWOPS034614 | S. cerevisiae |                   |
| Y12         | S. cerevisiae |                   |
| DBVPG6765   | S. cerevisiae |                   |
| DBVPG6044   | S. cerevisiae |                   |
| CBS432      | S. paradoxus  | ✓                 |
| UFRJ50816   | S. paradoxus  | ✓                 |
| N44         | S. paradoxus  |                   |
| UWOPS919171 | S. paradoxus  |                   |
| YPS138      | S. paradoxus  |                   |

Table: 12 yeast strains from two related clades were used in our analysis. Five strains were selected to be included in the graphs while the remaining seven were used for variant calling only. {#tbl:strains}

#### Construction of the *construct graph*

For the first graph (called *construct graph* throughout the paper), the most common graph construction method was applied.
It requires a linear reference genome and a VCF file of variants on that reference to build the graph.
As reference genome, the PacBio assembly of the S.c. S288C strain was chosen because this strain was used for the S. cerevisiae genome reference assembly.
To obtain variants three methods for SV detection from genome assemblies were combined: Assemblytics [@doi:10.1093/bioinformatics/btw369] (commit df5361f), AsmVar (commit 5abd91a) [@doi:10.1186/s13742-015-0103-4] and paftools (version 2.14-r883) [@doi:10.1093/bioinformatics/bty191].
All three methods were run to detect SVs between the PacBio assembly of reference strain S.c. S288C and the PacBio assemblies of each of the four other selected yeast strains.
The union of variants detected by the three methods was produced (using bedtools [̍@doi:10.1093/bioinformatics/btq033]) and variants with a reciprocal overlap of at least 50% were combined to avoid duplication in the union set.
These union sets of variants for each of the four selected (and non-reference) strains were merged and another deduplication step was applied to combine variants with a reciprocal overlap of at least 90%.
The resulting total set of variants in VCF format and the linear reference genome were used to build the *construct graph* with `vg construct`.

#### Construction of the *cactus graph*

For the second graph (called *cactus graph* throughout the paper), an alternative graph construction methods directly from de novo genome assemblies was applied.
First, the repeat-masked PacBio-assemblies of the five selected strains were aligned with our Cactus tool [@doi:10.1101/gr.123356.111].
Cactus requires a phylogenetic tree of the strains which was estimated using Mash [@doi:10.1186/s13059-016-0997-x] and PHYLIP.
Subsequently, the output file in HAL format was converted to a variant graph with hal2vg ([https://github.com/ComparativeGenomicsToolkit/hal2vg](https://github.com/ComparativeGenomicsToolkit/hal2vg)).

#### Calling and genotyping of SVs

Prior to variant calling, the Illumina short reads of all 12 yeast strains were mapped to both graphs using `vg map`.
The fractions of reads mapped with specific properties were measured using `vg view` and the JSON processor `jq`.
Then, `toil-vg call` (commit be8b6dadac5372081ae54fad868458656258948e from March 20, 2019) was used to analyze the mapped reads of each of the 11 non-reference strains and to call variants.
Thus, a separate variant callset was obtained for each of the strains and both graphs.
To evaluate the callsets, a sample graph was generated for each callset using `vg construct` and `vg mod` on the reference assembly S.c. S288C and the callset.
A sample graph is a graph representation of the callset.
Subsequently, short reads from the respective strains were mapped to each sample graph using `vg map`.
The resulting alignments were analyzed with `vg view` and the `jq`.
