## Introduction {.page_break_before}

A structural variant (SV) is a genomic mutation involving 50 or more base pairs.
SVs can take several forms such as deletions, insertions, inversions, translocations or other complex events.  
Due to their greater size, SVs often have a larger impact on phenotype than smaller events such as single nucleotide variants (SNVs) and small insertions and deletions (indels).
[//]: # (I think it might be a good idea to have a reference for the above statement, since at least for me it was not immediately obvious that it is the case. We could maybe use this https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5406250/. From the abstract (I have only skimmed the rest of the paper) it sounds like they are corroborating the statement.)
Indeed, SVs have long been associated with developmental disorders, cancer and other complex diseases and phenotypes[@doi:10.1038/nrg3373]. 

Despite their importance, SVs remain much more poorly studied than their smaller mutational counterparts.
This discrepancy stems from technological limitations: Short read sequencing has provided the basis of most modern genome sequencing studies due to its high base-level accuracy and relatively low cost, however, it is poorly suited for discovering SVs. 
The central obstacle is in mapping short reads to the human reference genome.
It is generally difficult or impossible to unambiguously map a short read if the sample whose genome is being analyzed differs substantially from the reference at the read's location.
The large size of SVs virtually guarantees that this will be the case.
For example, if the read derives from the middle of a large insertion relative to the reference, there is no sequence in the reference that corresponds to a correct mapping.
The best result a read mapper could hope to produce would be to leave it unmapped.
Moreover, SVs often lie in repeat-rich regions, which further frustrate read mapping algorithms.

Short reads can be more effectively used to genotype known SVs.
This is important, as even though efforts to catalog SVs with other technologies have been highly successful, their cost currently prohibits their use in large-scale studies that require hundreds or thousands of samples such as disease association studies.
Traditional SV genotypers start from reads that were mapped to a reference genome, extracting aberrant mapping that might support the presence of the SV of interest.
State-of-art methods like SVTyper[@tag:svtyper] and Delly[@tag:delly] typically focus on split reads and paired reads mapped too close or too far from each other.
These discordant reads are tallied and remapped to the reference sequence modified with the SV of interest in order to genotype deletions, insertions, duplications, inversions and translocations.
SMRT-SV2 uses a different approach: the reference genome is augmented with SV-containing sequences as alternate contigs and the resulting mappings are evaluated with a machine learning model trained for this purpose[@tag:audano2019].

The catalog of known SVs in human is quickly expanding.
Several large-scale projects have used short-read sequencing and extensive discovery pipelines on large cohorts, compiling catalogs with tens of thousands of SVs in humans[@tag:kgp2015; @tag:gonl].
More recent studies using long-read or linked-read sequencing have produced large catalogs of structural variation, the majority of which was novel and sequence-resolved[@tag:chaissonCHM; @tag:smrtsv; @doi:10.1038/s41467-017-01343-4; @doi:10.1038/nmeth.4366; @tag:audano2019].
These technologies are also enabling the production of high-quality de novo genome assemblies[@tag:chaissonCHM; @doi:10.1038/nbt.4060], and large blocks of haplotype-resolved sequences[@doi:10.1038/nmeth.4035].
Such technical advances promise to expand the amount of known genomic variation in humans in the near future, and further power SV genotyping studies.
Representing known structural variation in the wake of increasingly larger datasets poses a considerable challenge, however.
Standard formats such as VCF are unwieldy when used for SVs due to ambiguity in their specification and limited support across tools.
[//]: # (I am a bit unsure what is meant by "limited support across tools" here? I would say that VCF is the most supported format when it comes to representing variation, including structural variation. Or am I misunderstanding it?)
Another strategy consists in incorporating SVs into a linear pan-genome reference via alt contigs, but it also has serious drawbacks.
Alt contigs tend to increase mapping ambiguity.
In addition, it is unclear how to scale this approach as SV catalogs grow.

Pan-genome graph reference representations offer an attractive approach for storing genetic variation of all types[@tag:patenGRrev]. 
The graph structure can represent SVs as succinctly and directly as point mutations. 
Moreover, including known variants in the reference makes both read mapping and variant calling variant-aware.
This leads to benefits in terms of accuracy and sensitivity[@tag:vgnbt; @tag:bakeoff; @doi:10.1038/s41588-018-0316-4].
In addition, different variant types can be called simultaneously and scored consistently across types by a unified framework.

vg is the first openly available variation graph tool to scale to multi-gigabase genomes.
It provides read mapping, variant calling and visualization tools[@tag:vgnbt].
In addition, vg can build graphs both from variant catalogs in the VCF format and from assembly alignments.

Other tools have used genome graphs specifically to genotype variants.
GraphTyper realigns mapped reads to a graph built from known SNVs and short indels using a sliding-window approach[@tag:graphtyper].
BayesTyper first builds a set of graphs from known variants including SVs, then genotypes variants by comparing the distribution of k-mers in the sequencing reads with the k-mers of haplotype candidate paths in the graph[@tag:bayestyper].
These graph-based approaches showed clear advantages over standard methods that use only the linear reference.

In this work, we present a variation graph-based SV genotyping framework implemented using vg. 
We show that this method is capable of genotyping known deletions, insertions and inversions.
This is true even when there is small errors in the location of the SVs breakpoints.
Starting from SVs discovered in recent long-read sequencing studies[@tag:audano2019;@tag:hgsvc;@doi:10.1038/sdata.2016.25;@doi:10.1101/281006], we evaluated the genotyping accuracy using simulated and real Illumina reads. 
We also compared vg's performance with state-of-the-art SV genotypers: SVTyper[@tag:svtyper], Delly[@tag:delly], BayesTyper[@tag:bayestyper] and SMRT-SV2[@tag:audano2019].
Across all three datasets that we tested, vg is the best performing SV genotyper on real short-read data for all SV types.
In addition, we show that building graphs from the alignment of de novo assemblies leads to better genotyping performance.

