## Discussion

<!-- Discuss why vg is doing better -->
Overall, vg was the most accurate SV genotyper in our benchmarks.
These results show that variant calling benefits from variant-aware read mapping, a finding consistent with previous studies[@tag:vgnbt; @tag:bakeoff; @doi:10.1038/s41588-018-0316-4; @tag:graphtyper; @tag:bayestyper].
<!-- Other advantages: SV representation, unified variant calling. -->
In addition to variant-aware mapping, vg uses a unified framework to call and score different variant types simultaneously. 

Variation graphs that contain known SNVs, indels and SVs could serve as a richer reference for large scale genomics projects.
More and more large-scale projects are using low cost short-read technologies to sequence the genomes of thousands to hundreds of thousands of individuals (e.g. the Pancancer Analysis of Whole Genomes[@url:https://dcc.icgc.org/pcawg], the Genomics England initiative[@url:https://www.genomicsengland.co.uk], and the TOPMed consortium[@url:https://www.nhlbiwgs.org/]). 
Our method substantially improves on the state of the art for how accurately known SVs can be genotyped with this type of data.
Thus, it expands the scope of genomic variation that can be assayed at such a large scale with low cost sequencing. 

[//]: # (In my opinion, we could cut the two sentences about BayesTyper. We compared against four other genotyping algorithms, it seems a little arbitrary to emphasize our advantage against one other one on one aspect of performance--especially since this subject matter is mirrored in the results section)
<!-- Input data quality: "sequence-resolved", break-point fine-tuning. -->
A particular advantage of our method is that it does not require exact breakpoint resolution in the variant library.
Our simulations showed that vg's SV genotyping algorithm is robust to errors of as much as 10 bp in breakpoint location.
However, there is an upper limit.
vg cannot accurately genotype variants with much higher uncertainty in the breakpoint location (like those discovered through read coverage analysis).
vg's robustness to breakpoint errors helped it achieve higher accuracy in real data than BayesTyper, the other genome graph-based method we tested.
Unlike vg, BayesTyper relies on exact matches between reads and graph paths, which makes it sensitive to breakpoint uncertainty.
Of note, vg is also capable of fine-tuning SV breakpoints by augmenting the graph with differences observed in read alignments.
Simulations showed that this approach can usually correct small errors in SV breakpoints (Figure {@fig:simerror-bkpt} and Table {@tbl:simerror-bkpt}).

<!-- Already superior but will only get better with new vg dev -->
The vg toolkit is under active development.
Read mapping is an area of constant improvement in terms of both computational efficiency and accuracy.
One technique under development is the integration of haplotype information into the process of read mapping and variant calling. 
We believe vg's SV genotyping algorithm stands to benefit from this technique. 
Haplotype information can be used to limit the variant search space and provide stronger priors on variant combinations.
Faster mapping also helps increase the scale on which this method can be used practically.

In our benchmarks, other methods were superior in a handful datasets and situations, primarily when genotyping deletions.
However, even in most of these cases, vg had the best accuracy when evaluating only the presence or absence of the variants.
This suggests that the performance shortfall can be attributed to the genotyping algorithm rather than the mapping pipeline.
We hope to address these issues in a future release.

<!-- Benefits of de novo assemblies -->
Our results suggest that constructing a graph from de novo assembly alignment instead of a VCF leads to better SV genotyping.
High quality de novo assemblies for human are becoming more and more common due to improvements in technologies like optimized mate-pair libraries[@tag:denmark] and long-read sequencing[@doi:10.1038/nbt.4060].
We expect the future graphs to include information from the alignment of numerous de novo assemblies.
We are presently working on scaling our assembly-based pipeline to human-sized genome assemblies.
Another challenge is creating genome graphs that integrate assemblies with variant-based data resources.
One possible approach is to progressively align assembled contigs into variation graphs constructed from variant libraries.
Methods for doing so are still experimental.

## Conclusion

In this study, the vg toolkit was compared to existing SV genotypers across several high-quality SV catalogs.
We showed that its method of mapping reads to a variation graph leads to better SV genotyping compared to other state of the art methods.
This work introduces a flexible strategy to integrate the growing number of SVs being discovered with higher resolution technologies into a unified framework of genome inference.
This study also shows the benefit of directly utilizing de novo assemblies rather than variant catalogs to integrate SVs in genome graphs.
